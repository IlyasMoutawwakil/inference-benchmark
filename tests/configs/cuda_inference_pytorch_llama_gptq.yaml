defaults:
  - backend: pytorch
  # order of inheritance, last one overrides previous ones
  - _base_ # inherits from base config
  - _inference_ # inherits from inference config
  - _cuda_ # inherits from cpu config
  - _self_ # hydra 1.1 compatibility

experiment_name: cuda_inference_pytorch_gptq

backend:
  model: TheBloke/TinyLlama-1.1B-Chat-v0.3-GPTQ
  quantization_config:
    exllama_config:
      version: 2

# hydra/cli specific settings
hydra:
  sweeper:
    params:
      backend.no_weights: false,true
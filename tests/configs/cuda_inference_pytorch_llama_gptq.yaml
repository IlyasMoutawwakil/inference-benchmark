defaults:
  - backend: pytorch # default backend
  - launcher: process # default launcher
  - benchmark: inference # default benchmark
  - experiment # inheriting experiment schema
  - _self_ # for hydra 1.1 compatibility
  - override hydra/job_logging: colorlog # colorful logging
  - override hydra/hydra_logging: colorlog # colorful logging

experiment_name: cuda_inference_pytorch_llama_gptq  

backend:
  device: cuda
  device_ids: 0
  model: TheBloke/Llama-2-7B-GPTQ
  # hub_kwargs:
  #   trust_remote_code: true
  quantization_config:
    # disable_exllama: true
    exllama_config:
      version: 2

launcher:
  device_isolation: true

benchmark:
  memory: true
  latency: true
  energy: true

# hydra/cli specific settings
hydra:
  sweeper:
    params:
      backend.no_weights: true,false
  run:
    # where to store run results
    dir: runs/${experiment_name}
  sweep:
    # where to store sweep results
    dir: sweeps/${experiment_name}
  job:
    # change working directory to the run directory
    chdir: true
    env_set:
      # set environment variable OVERRIDE_BENCHMARKS to 1
      # to not skip benchmarks that have been run before
      OVERRIDE_BENCHMARKS: 1
defaults:
  - benchmark: training
  - backend: pytorch
  - _base_ # inherits from base config
  - _self_ # for hydra 1.1 compatibility

experiment_name: ${device}_${backend}_${benchmark}_${task}_peft

model: hf-internal-testing/tiny-random-gpt2
task: text-generation
device: cuda

benchmark:
  dataset_shapes:
    dataset_size: 1600
    sequence_length: 256

backend:
  peft_strategy: lora
  peft_config:
    task_type: CAUSAL_LM

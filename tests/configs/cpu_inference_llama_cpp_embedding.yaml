defaults:
  # order of inheritance, last one overrides previous ones
  - _base_ # inherits from base config
  - _cpu_ # inherits from cpu config
  - _inference_ # inherits from inference config
  - _self_ # hydra 1.1 compatibility
  - override backend: llama_cpp

name: inference_llama_cpp_embedding

backend:
  model: nomic-ai/nomic-embed-text-v1.5-GGUF
  filename: nomic-embed-text-v1.5.Q4_0.gguf

scenario:
  input_shapes:
    batch_size: 1
    sequence_length: 256
  generate_kwargs:
    max_new_tokens: 100
    min_new_tokens: 100

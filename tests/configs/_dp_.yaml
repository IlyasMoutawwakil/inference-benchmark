# Data Parallel (DP) training
experiment_name: ${device}_${backend.name}_${benchmark.name}_${task}_dp

benchmark:
  dataset_shapes:
    dataset_size: 1600
    sequence_length: 256
  training_arguments:
    per_device_train_batch_size: 8

hydra:
  job:
    env_set:
      CUDA_VISIBLE_DEVICES: 0,1

defaults:
  - backend: pytorch # default backend
  - launcher: inline # default launcher
  - benchmark: training # default benchmark
  - experiment # inheriting from experiment config
  - _self_ # for hydra 1.1 compatibility
  - override hydra/job_logging: colorlog # colorful logging
  - override hydra/hydra_logging: colorlog # colorful logging

experiment_name: llama-experiment
model: llama-2-model
device: cuda

backend:
  no_weights: true
  torch_dtype: float16
  continuous_isolation: true

benchmark:
  warmup_steps: 40
  dataset_shapes:
    dataset_size: 160
    sequence_length: 256
  training_arguments:
    max_steps: 140
    per_device_train_batch_size: 1

hydra:
  run:
    dir: experiments/${oc.env:HOSTNAME}/${model}/${experiment_name}
  sweep:
    dir: experiments/${oc.env:HOSTNAME}/${model}/${experiment_name}
    subdir: ${benchmark.training_arguments.per_device_train_batch_size}
  job:
    chdir: true
    env_set:
      CUDA_VISIBLE_DEVICES: 0
      CUDA_DEVICE_ORDER: PCI_BUS_ID
  sweeper:
    params:
      benchmark.training_arguments.per_device_train_batch_size: 1,2,4,8,16,32,64,128
      model: NousResearch/Llama-2-7b-hf,NousResearch/Llama-2-13b-hf

defaults:
  - _base_
  - _self_
  - override launcher: torchrun

experiment_name: fp16+gptq+exllamav2+dp=2

launcher:
  nproc_per_node: 2
  rdzv_endpoint: localhost:29533

backend:
  # for some reason core gets dumped
  # with dummy weights + exllamav2
  no_weights: false
  quantization_scheme: gptq
  quantization_config:
    exllama_config:
      version: 2

hydra:
  job:
    env_set:
      CUDA_VISIBLE_DEVICES: 0,1
  sweeper:
    params:
      model: TheBloke/LLaMa-7B-GPTQ,TheBloke/LLaMa-13B-GPTQ,TheBloke/LLaMa-65B-GPTQ

defaults:
  - _base_
  - _self_
  - override launcher: process

experiment_name: fp16+gptq+exllamav1

backend:
  # for some reason core gets dumped
  # with 65B + exllamav1
  no_weights: false
  quantization_scheme: gptq
  quantization_config:
    exllama_config:
      version: 1

hydra:
  sweeper:
    params:
      model: TheBloke/LLaMa-7B-GPTQ,TheBloke/LLaMa-13B-GPTQ,TheBloke/LLaMa-65B-GPTQ

defaults:
  - benchmark
  - backend: pytorch
  - launcher: process
  - scenario: energy_star
  - _base_
  - _self_

name: text_generation_mixtral-8x22B

launcher:
  device_isolation: true
  device_isolation_action: warn

backend:
  device: cuda
  device_ids: 0,1,2,3,4,5,6,7
  no_weights: true
  model: mistral-community/Mixtral-8x22B-v0.1
  task: text-generation
  device_map: auto

scenario:
  dataset_name: EnergyStarAI/text_generation
  num_samples: 1000
  text_column_name: text
  truncation: True
  input_shapes:
    batch_size: 1

  generate_kwargs:
    max_new_tokens: 10
    min_new_tokens: 10

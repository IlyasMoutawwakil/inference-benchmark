name: CLI ROCm Pytorch Multi-GPU Tests

on:
  workflow_dispatch:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

concurrency:
  cancel-in-progress: true
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}

jobs:
  run_cli_rocm_pytorch_multi_gpu_tests:
    runs-on: [multi-gpu, amd-gpu, mi250, ci]

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Target devices
        run: |
          echo "DEVICE0: $DEVICE0"
          echo "DEVICE1: $DEVICE1"
          echo "DEVICE0=$DEVICE0" >> $GITHUB_ENV
          echo "DEVICE1=$DEVICE1" >> $GITHUB_ENV

      - name: Run tests
        uses: addnab/docker-run-action@v3
        env:
          DEVICE0: ${{ env.DEVICE0 }}
          DEVICE1: ${{ env.DEVICE1 }}
        with:
          image: ghcr.io/huggingface/optimum-benchmark:latest-rocm
          options: |
            --rm
            --shm-size 64G
            --device /dev/kfd
            --device /dev/dri/${{ env.DEVICE0 }}
            --device /dev/dri/${{ env.DEVICE1 }}
            --volume ${{ github.workspace }}:/workspace
            --workdir /workspace
          run: |
            pip install -e .[testing,diffusers,timm,deepspeed,peft,autoawq-rocm,auto-gptq-rocm]
            pytest -x -s -k "cli and cuda and pytorch and (dp or ddp or device_map or deepspeed) and not (bnb or awq)"

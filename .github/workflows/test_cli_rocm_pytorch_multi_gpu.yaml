name: CLI ROCm Pytorch Multi-GPU Tests

on:
  workflow_dispatch:
  push:
    branches:
      - main
    paths:
      - .github/workflows/test_cli_rocm_pytorch_multi_gpu.yaml
      - "optimum_benchmark/**"
      - "docker/**"
      - "tests/**"
      - "setup.py"
  pull_request:
    branches:
      - main
    paths:
      - .github/workflows/test_cli_rocm_pytorch_multi_gpu.yaml
      - "optimum_benchmark/**"
      - "docker/**"
      - "tests/**"
      - "setup.py"

concurrency:
  cancel-in-progress: true
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}

env:
  IMAGE: ghcr.io/huggingface/optimum-benchmark:latest-rocm

jobs:
  run_cli_rocm_pytorch_multi_gpu_tests:
    runs-on: [multi-gpu, amd-gpu, mi250, ci]

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set target devices
        run: |
          echo "DEVICE0:$DEVICE0"
          echo "DEVICE1:$DEVICE1"
          echo "DEVICE0=$DEVICE0" >> $GITHUB_ENV
          echo "DEVICE1=$DEVICE1" >> $GITHUB_ENV

      - name: Unroot docker image
        run: |
          docker build --build-arg IMAGE=${{ env.IMAGE }} --build-arg USER_ID=$(id -u) --build-arg GROUP_ID=$(id -g) -t ${{ env.IMAGE }}-unroot docker/unroot

      - name: Run tests
        uses: addnab/docker-run-action@v3
        env:
          DEVICE0: ${{ env.DEVICE0 }}
          DEVICE1: ${{ env.DEVICE1 }}
        with:
          image: ${{ env.IMAGE }}-unroot
          options: |
            --rm
            --shm-size 64G
            --device /dev/kfd
            --device /dev/dri/${{ env.DEVICE0 }}
            --device /dev/dri/${{ env.DEVICE1 }}
            --volume ${{ github.workspace }}:/workspace
            --workdir /workspace
          run: |
            pip install -e .[testing,diffusers,timm,deepspeed,peft,autoawq,auto-gptq]
            pytest -x -s -k "cli and cuda and pytorch and (dp or ddp or device_map or deepspeed) and not (bnb or awq)"
